# Data Setup Guide

## ğŸ“‹ Required Data Files

This system requires property data to function. You have two options:

### Option 1: Use Kaggle Dataset (Recommended for Getting Started)

1. **Download the dataset**:
   - Visit: https://www.kaggle.com/datasets/rohanchatse/pune-house-prices
   - Download `pune_house_prices.csv`

2. **Place the file**:
   ```
   data/pune_house_prices.csv
   ```

3. **Run the pipeline**:
   ```bash
   python main.py
   ```

### Option 2: Use Your Own Scraped Data

If you've scraped property data from MagicBricks or other sources:

1. **Place scraped CSV files** in the `scrape/` directory:
   ```
   scrape/magicbricks_koregaon_park_browser.csv
   scrape/magicbricks_hinjewadi_browser.csv
   scrape/magicbricks_kharadi_partial.csv
   ```

2. **Consolidate the data**:
   ```bash
   python scripts/consolidate_scraped_data.py
   ```
   
   This creates: `data/pune_house_prices.csv`

3. **Enhance with additional features** (optional):
   ```bash
   python scripts/enhance_property_data.py
   ```
   
   This creates: `data/pune_house_prices_enhanced.csv`
   - Adds RERA registration status
   - Calculates rental yields
   - Adds affordability metrics

4. **Run the pipeline**:
   ```bash
   python main.py
   ```

---

## ğŸ“ Expected File Structure

After setup, your project should look like:

```
broker_sentiment/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pune_house_prices.csv          # Main property data (required)
â”‚   â”œâ”€â”€ pune_house_prices_enhanced.csv # Enhanced data (optional)
â”‚   â””â”€â”€ sentiment_corpus.json          # Generated by pipeline
â”œâ”€â”€ outputs/                            # Generated by pipeline
â”‚   â”œâ”€â”€ locality_sentiment.csv
â”‚   â”œâ”€â”€ locality_rankings.csv
â”‚   â”œâ”€â”€ full_predictions.csv
â”‚   â”œâ”€â”€ affordability_analysis.csv
â”‚   â””â”€â”€ ... (other generated files)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ demand_predictor.joblib        # Generated by pipeline
â””â”€â”€ scrape/                             # Your scraped data (if any)
```

---

## ğŸ”„ Pipeline Execution Order

Run these in order:

### 1. Data Preparation (First Time Only)

```bash
# If using scraped data:
python scripts/consolidate_scraped_data.py

# Optional enhancements:
python scripts/enhance_property_data.py
```

### 2. Run Main Pipeline

```bash
# Full pipeline with fresh sentiment data:
python main.py --generate-data

# Use existing sentiment data:
python main.py

# Test mode (faster, smaller dataset):
python main.py --test-mode
```

This will:
1. âœ“ Generate synthetic sentiment data (or load existing)
2. âœ“ Analyze sentiment using NLP
3. âœ“ Aggregate sentiment by locality
4. âœ“ Merge property data with sentiment
5. âœ“ Train demand prediction model
6. âœ“ Generate insights and recommendations
7. âœ“ Save all outputs

### 3. Launch Dashboard

```bash
streamlit run dashboard.py
```

---

## ğŸ“Š Data Requirements

### Minimum Required Columns in `pune_house_prices.csv`:

- `area` - Locality name (e.g., "Koregaon Park", "Hinjewadi")
- `price` - Property price in INR
- `square_feet` - Property size
- `bedrooms` - Number of bedrooms
- `bathrooms` - Number of bathrooms
- `balcony` - Number of balconies
- `parking` - Number of parking spaces
- `property_age` or `year_built` - Age/year of construction

### Optional Enhanced Columns:

- `rera_registered` - Boolean, RERA compliance
- `avg_rental_yield` - Calculated rental yield percentage
- `min_annual_income` - Minimum income for affordability

---

## âš™ï¸ Configuration

Edit `config.py` to customize:

### Localities List

```python
PUNE_LOCALITIES = [
    "Koregaon Park",
    "Hinjewadi", 
    "Kharadi",
    # Add more localities as needed
]
```

### Sentiment Keywords

Customize sentiment analysis keywords in `SENTIMENT_CATEGORIES` dictionary.

### Model Parameters

Tune XGBoost model in `MODEL_PARAMS` dictionary.

---

## ğŸ§ª Testing Your Setup

### Quick Test

```bash
# Run in test mode (uses smaller dataset)
python main.py --test-mode

# Expected output:
# âœ“ Properties loaded
# âœ“ Sentiment analyzed
# âœ“ Model trained
# âœ“ Insights generated
```

### Verify Outputs

Check that these files were created:

```bash
ls outputs/
# Should show:
# - locality_sentiment.csv
# - locality_rankings.csv  
# - full_predictions.csv
# - sentiment_alerts.json
# - builder_recommendations.json
# - model_report.json
```

### Test Dashboard

```bash
streamlit run dashboard.py
```

Navigate to http://localhost:8501 and verify:
- âœ“ All tabs load
- âœ“ Map shows localities
- âœ“ Rankings table displays
- âœ“ Demand predictor works

---

## ğŸ”§ Troubleshooting

### Error: "FileNotFoundError: pune_house_prices.csv"

**Solution**: Download the Kaggle dataset and place in `data/` directory.

### Error: "No sentiment data available"

**Solution**: Run pipeline with `--generate-data` flag:
```bash
python main.py --generate-data
```

### Warning: "No enhanced data found"

**Info**: This is optional. Run to add RERA and rental yield features:
```bash
python scripts/enhance_property_data.py
```

### Dashboard shows "No data found"

**Solution**: Run the pipeline first:
```bash
python main.py
```

---

## ğŸ“ Data Privacy & Ethics

- **Scraped Data**: Ensure compliance with website terms of service
- **Personal Data**: Do not include personal information in datasets
- **API Keys**: Never commit API keys to git
- **Synthetic Data**: The system generates synthetic sentiment data for demonstration

---

## ğŸš€ Quick Start (TL;DR)

```bash
# 1. Download Kaggle dataset to data/pune_house_prices.csv
# 2. Run pipeline
python main.py

# 3. Launch dashboard
streamlit run dashboard.py

# 4. Open http://localhost:8501
```
